{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Traffic sign detection and classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from xml.dom import minidom\n",
    "from os import walk\n",
    "import pandas as pd\n",
    "import cv2 as cv\n",
    "import numpy as np\n",
    "from sklearn import metrics\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "filenames = next(walk(\"res/annotations\"), (None, None, []))[2]  # [] if no file\n",
    "\n",
    "signs = []\n",
    "\n",
    "for annotation in filenames:\n",
    "    # parse an xml file by name\n",
    "    file = minidom.parse(\"res/annotations/\" + annotation)\n",
    "\n",
    "    #use getElementsByTagName() to get tag\n",
    "    path = \"res/images/\" + file.getElementsByTagName('filename')[0].firstChild.data\n",
    "    filename = file.getElementsByTagName('filename')[0].firstChild.data\n",
    "    name = file.getElementsByTagName('name')[0].firstChild.data\n",
    "    # truncated = file.getElementsByTagName('truncated')[0].firstChild.data\n",
    "    # occluded = file.getElementsByTagName('occluded')[0].firstChild.data\n",
    "    # difficult = file.getElementsByTagName('difficult')[0].firstChild.data\n",
    "\n",
    "    if name == \"trafficlight\":\n",
    "        continue\n",
    "\n",
    "    signs.append([filename, name, path])\n",
    "\n",
    "df = pd.DataFrame(signs, columns=['filename', 'name', 'path'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def condition_classes(s):\n",
    "    if s['name'] == 'speedlimit':\n",
    "        return 0\n",
    "    elif s[\"name\"] == 'crosswalk':\n",
    "        return 1\n",
    "    elif s[\"name\"] == \"stop\":\n",
    "        return 2\n",
    "\n",
    "\n",
    "df[\"class\"] = df.apply(condition_classes, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def concatenate_and_write(row):\n",
    "    img = cv.imread(row.path)\n",
    "    hist = cv.imread(\"output/histogram/\" + row.filename)\n",
    "    segm = cv.imread(\"output/segmentation/\" + row.filename)\n",
    "    post = cv.imread(\"output/post_processing/\" + row.filename)\n",
    "\n",
    "    vis = np.concatenate((img, hist, segm, post), axis=1)\n",
    "\n",
    "    cv.imwrite(\"output/concatenated/\" + row.filename, vis)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1 - Histogram equalization\n",
    "\n",
    "TODO - Need to improve the histogram equalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def apply_histogram_equalization(row):\n",
    "    img = cv.imread(row.path)\n",
    "    lab = cv.cvtColor(img, cv.COLOR_BGR2LAB)\n",
    "\n",
    "    clahe = cv.createCLAHE(clipLimit=10.0,tileGridSize=(8,8))\n",
    "\n",
    "    lab[...,0] = clahe.apply(lab[...,0])\n",
    "\n",
    "    out = cv.cvtColor(lab, cv.COLOR_LAB2BGR)\n",
    "\n",
    "    cv.imwrite(\"output/histogram/\" + row.filename, out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "df.apply(apply_histogram_equalization, axis=1);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Step 2 - Segmentation by Color"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def apply_segmentation(row):\n",
    "    img = cv.imread(row.path)\n",
    "    # TODO - work on histogram equalization\n",
    "    img_hist = cv.imread(\"output/histogram/\" + row.filename)\n",
    "    img_hsv = cv.cvtColor(img_hist, cv.COLOR_BGR2HSV)\n",
    "\n",
    "    lower_red_m1 = (0, 70, 60)\n",
    "    upper_red_m1 = (10, 255, 255)\n",
    "\n",
    "    lower_red_m2 = (170, 70, 60)\n",
    "    upper_red_m2 = (180, 255, 255)\n",
    "\n",
    "    lower_blue_m3 = (94, 127, 20)\n",
    "    upper_blue_m3 = (126, 255, 200)\n",
    "\n",
    "    mask1 = cv.inRange(img_hsv, lower_red_m1, upper_red_m1)\n",
    "    mask2 = cv.inRange(img_hsv, lower_red_m2, upper_red_m2)\n",
    "    mask3 = cv.inRange(img_hsv, lower_blue_m3, upper_blue_m3)\n",
    "\n",
    "    mask = mask1 + mask2 + mask3\n",
    "\n",
    "    # out = cv.bitwise_and(img_hist, img_hist, mask=mask)\n",
    "\n",
    "    cv.imwrite(\"output/segmentation/\" + row.filename, mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "df.apply(apply_segmentation, axis=1);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Step 3 - Post-Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def apply_post_processing(row):\n",
    "    img = cv.imread(row.path)\n",
    "    segm_img = cv.imread(\"output/segmentation/\" + row.filename, cv.IMREAD_GRAYSCALE)\n",
    "\n",
    "    # apply median filter to remove noise\n",
    "    out = cv.medianBlur(segm_img, 5)\n",
    "    rows, cols = out.shape\n",
    "\n",
    "    # Taking a matrix of size 5 as the kernel\n",
    "    kernel = np.ones((5, 5), np.uint8)\n",
    "\n",
    "    # morphological operations\n",
    "    out = cv.morphologyEx(out, cv.MORPH_CLOSE, kernel, iterations=4)\n",
    "\n",
    "    # remove small and weird objects\n",
    "    contours, hierarchy = cv.findContours(out, cv.RETR_TREE, cv.CHAIN_APPROX_SIMPLE)[-2:]\n",
    "    for contour in contours:\n",
    "        x, y, w, h = cv.boundingRect(contour)\n",
    "        aspect_ratio = float(w) / h\n",
    "        if cv.contourArea(contour) < 1 / 1500.0 * rows * cols and (aspect_ratio > 0.5 or aspect_ratio < 1.3):\n",
    "            out = cv.fillPoly(out, pts=contour, color=(0, 0, 0))\n",
    "\n",
    "    mask = np.full(img.shape, 0, \"uint8\")\n",
    "    contours, hierarchies = cv.findContours(out, cv.RETR_TREE, cv.CHAIN_APPROX_NONE)[-2:]\n",
    "    for cnt in contours:\n",
    "        cv.drawContours(mask, [cnt], -1, (255, 255, 255), -1)\n",
    "\n",
    "    mask = cv.cvtColor(mask, cv.COLOR_BGR2GRAY)\n",
    "    # morphological operations\n",
    "    out = cv.erode(mask, kernel, iterations=1)\n",
    "    out = cv.dilate(mask, kernel, iterations=1)\n",
    "\n",
    "    cv.imwrite(\"output/post_processing/\" + row.filename, out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "df.apply(apply_post_processing, axis=1);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "df.apply(concatenate_and_write, axis=1);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4 - Shape Recognition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def shape_recognition(row):\n",
    "    img = cv.imread(row.path)\n",
    "    processed = cv.imread(\"output/post_processing/\" + row.filename, 0)\n",
    "\n",
    "    _, thresh = cv.threshold(processed, 240, 255, cv.CHAIN_APPROX_NONE)\n",
    "    contours, _ = cv.findContours(thresh, cv.RETR_TREE, cv.CHAIN_APPROX_NONE)[-2:]\n",
    "\n",
    "    contours = sorted(contours, key=lambda x: -cv.contourArea(x))[:10]\n",
    "\n",
    "    shapes = []\n",
    "\n",
    "    for contour in contours:\n",
    "        if float(cv.contourArea(contour) / (img.shape[0]*img.shape[1])) >= 0.95:\n",
    "            continue\n",
    "        approx = cv.approxPolyDP(contour, 0.01*cv.arcLength(contour, True), True)\n",
    "        if len(approx) == 4:\n",
    "            shapes.append((\"rectangle\", cv.contourArea(contour), (cv.boundingRect(contour))))\n",
    "        elif len(approx) == 8:\n",
    "            shapes.append((\"octagon\", cv.contourArea(contour), (cv.boundingRect(contour))))\n",
    "        elif len(approx) > 8:\n",
    "            shapes.append((\"circle\", cv.contourArea(contour), (cv.boundingRect(contour))))\n",
    "\n",
    "    return shapes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "df[\"shapes\"] = df.apply(shape_recognition, axis=1);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def classify(row):\n",
    "    shapes_info = row.shapes\n",
    "    if len(shapes_info) == 0:\n",
    "        return -1\n",
    "\n",
    "    shapes = [x[0] for x in shapes_info]\n",
    "    shape = shapes[0]\n",
    "\n",
    "    if shape == 'circle':\n",
    "        return 0\n",
    "    elif shape == 'rectangle':\n",
    "        return 1\n",
    "    elif shape == 'octagon':\n",
    "        return 2\n",
    "\n",
    "    return -1\n",
    "\n",
    "df[\"classification\"] = df.apply(classify, axis=1);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classes:\n",
      " 0    652\n",
      "1     88\n",
      "2     76\n",
      "Name: class, dtype: int64\n",
      "Detected classes:\n",
      "  0    716\n",
      " 2     57\n",
      "-1     25\n",
      " 1     18\n",
      "Name: classification, dtype: int64\n",
      "Accuracy Total: 78.43%\n",
      "Accuracy Signs Found: 80.91%\n"
     ]
    }
   ],
   "source": [
    "df_found = df[df[\"classification\"] != -1]\n",
    "\n",
    "accuracy_total = metrics.accuracy_score(df[\"class\"], df[\"classification\"])\n",
    "accuracy_found = metrics.accuracy_score(df_found[\"class\"], df_found[\"classification\"])\n",
    "\n",
    "print(\"Classes:\\n\", df[\"class\"].value_counts())\n",
    "print(\"Detected classes:\\n\", df[\"classification\"].value_counts())\n",
    "print(\"Accuracy Total: {:.02f}%\".format(accuracy_total*100))\n",
    "print(\"Accuracy Signs Found: {:.02f}%\".format(accuracy_found*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class 0: R:603|W:49\n",
      "Class 1: R:12|W:76\n",
      "Class 2: R:25|W:51\n"
     ]
    }
   ],
   "source": [
    "failed_0 = len(df[(df[\"class\"] == 0) & (df[\"classification\"] != 0)])\n",
    "failed_1 = len(df[(df[\"class\"] == 1) & (df[\"classification\"] != 1)])\n",
    "failed_2 = len(df[(df[\"class\"] == 2) & (df[\"classification\"] != 2)])\n",
    "\n",
    "right_0 = len(df[(df[\"class\"] == 0) & (df[\"classification\"] == 0)])\n",
    "right_1 = len(df[(df[\"class\"] == 1) & (df[\"classification\"] == 1)])\n",
    "right_2 = len(df[(df[\"class\"] == 2) & (df[\"classification\"] == 2)])\n",
    "\n",
    "\n",
    "print(\"Class 0: R:{}|W:{}\".format(right_0, failed_0))\n",
    "print(\"Class 1: R:{}|W:{}\".format(right_1, failed_1))\n",
    "print(\"Class 2: R:{}|W:{}\".format(right_2, failed_2))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
