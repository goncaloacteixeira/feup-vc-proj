{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Traffic sign detection and classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [],
   "source": [
    "from xml.dom import minidom\n",
    "from os import walk\n",
    "import pandas as pd\n",
    "import cv2 as cv\n",
    "import numpy as np\n",
    "from sklearn import metrics\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "filenames = next(walk(\"res/annotations\"), (None, None, []))[2]  # [] if no file\n",
    "\n",
    "signs = []\n",
    "\n",
    "for annotation in filenames:\n",
    "    # parse an xml file by name\n",
    "    file = minidom.parse(\"res/annotations/\" + annotation)\n",
    "\n",
    "    #use getElementsByTagName() to get tag\n",
    "    path = \"res/images/\" + file.getElementsByTagName('filename')[0].firstChild.data\n",
    "    filename = file.getElementsByTagName('filename')[0].firstChild.data\n",
    "    name = file.getElementsByTagName('name')[0].firstChild.data\n",
    "    # truncated = file.getElementsByTagName('truncated')[0].firstChild.data\n",
    "    # occluded = file.getElementsByTagName('occluded')[0].firstChild.data\n",
    "    # difficult = file.getElementsByTagName('difficult')[0].firstChild.data\n",
    "\n",
    "    if name == \"trafficlight\":\n",
    "        continue\n",
    "\n",
    "    signs.append([filename, name, path])\n",
    "\n",
    "df = pd.DataFrame(signs, columns=['filename', 'name', 'path'])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "def condition_classes(s):\n",
    "    if s['name'] == 'speedlimit':\n",
    "        return 0\n",
    "    elif s[\"name\"] == 'crosswalk':\n",
    "        return 1\n",
    "    elif s[\"name\"] == \"stop\":\n",
    "        return 2\n",
    "\n",
    "\n",
    "df[\"class\"] = df.apply(condition_classes, axis=1)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "def concatenate_and_write(row):\n",
    "    img = cv.imread(row.path)\n",
    "    hist = cv.imread(\"output/histogram/\" + row.filename)\n",
    "    segm = cv.imread(\"output/segmentation/\" + row.filename)\n",
    "    post = cv.imread(\"output/post_processing/\" + row.filename)\n",
    "\n",
    "    vis = np.concatenate((img, hist, segm, post), axis=1)\n",
    "\n",
    "    cv.imwrite(\"output/concatenated/\" + row.filename, vis)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Step 1 - Histogram equalization\n",
    "\n",
    "TODO - Need to improve the histogram equalization"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "def apply_histogram_equalization(row):\n",
    "    img = cv.imread(row.path)\n",
    "    # convert image from RGB to HSV\n",
    "    img_hsv = cv.cvtColor(img, cv.COLOR_BGR2HSV)\n",
    "    # Histogram equalisation on the V-channel\n",
    "    img_hsv[:, :, 2] = cv.equalizeHist(img_hsv[:, :, 2])\n",
    "    # convert image back from HSV to RGB\n",
    "    out = cv.cvtColor(img_hsv, cv.COLOR_HSV2BGR)\n",
    "\n",
    "    cv.imwrite(\"output/histogram/\" + row.filename, out)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "df.apply(apply_histogram_equalization, axis=1);"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Step 2 - Segmentation by Color"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "def apply_segmentation(row):\n",
    "    img = cv.imread(row.path)\n",
    "    # TODO - work on histogram equalization\n",
    "    # img_hist = cv.imread(\"output/histogram/\" + row.filename)\n",
    "    img_hist = img\n",
    "    img_hsv = cv.cvtColor(img_hist, cv.COLOR_BGR2HSV)\n",
    "\n",
    "    lower_red_m1 = (0, 70, 60)\n",
    "    upper_red_m1 = (10, 255, 255)\n",
    "\n",
    "    lower_red_m2 = (170, 70, 60)\n",
    "    upper_red_m2 = (180, 255, 255)\n",
    "\n",
    "    lower_blue_m3 = (94, 127, 20)\n",
    "    upper_blue_m3 = (126, 255, 200)\n",
    "\n",
    "    mask1 = cv.inRange(img_hsv, lower_red_m1, upper_red_m1)\n",
    "    mask2 = cv.inRange(img_hsv, lower_red_m2, upper_red_m2)\n",
    "    mask3 = cv.inRange(img_hsv, lower_blue_m3, upper_blue_m3)\n",
    "\n",
    "    mask = mask1 + mask2 + mask3\n",
    "\n",
    "    # out = cv.bitwise_and(img_hist, img_hist, mask=mask)\n",
    "\n",
    "    cv.imwrite(\"output/segmentation/\" + row.filename, mask)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "df.apply(apply_segmentation, axis=1);"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Step 3 - Post-Processing"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "def apply_post_processing(row):\n",
    "    img = cv.imread(row.path)\n",
    "    segm_img = cv.imread(\"output/segmentation/\" + row.filename, cv.IMREAD_GRAYSCALE)\n",
    "\n",
    "    # apply median filter to remove noise\n",
    "    out = cv.medianBlur(segm_img, 5)\n",
    "    rows, cols = out.shape\n",
    "\n",
    "    # Taking a matrix of size 5 as the kernel\n",
    "    kernel = np.ones((5, 5), np.uint8)\n",
    "\n",
    "    # morphological operations\n",
    "    out = cv.dilate(out, kernel, iterations=1)\n",
    "    out = cv.erode(out, kernel, iterations=1)\n",
    "\n",
    "    # remove small and weird objects\n",
    "    contours, hierarchy = cv.findContours(out, cv.RETR_TREE, cv.CHAIN_APPROX_SIMPLE)\n",
    "    for contour in contours:\n",
    "        x, y, w, h = cv.boundingRect(contour)\n",
    "        aspect_ratio = float(w) / h\n",
    "        if cv.contourArea(contour) < 1 / 1500.0 * rows * cols and (aspect_ratio > 0.5 or aspect_ratio < 1.3):\n",
    "            out = cv.fillPoly(out, pts=contour, color=(0, 0, 0))\n",
    "\n",
    "    mask = np.full(img.shape, 0, \"uint8\")\n",
    "    contours, hierarchies = cv.findContours(out, cv.RETR_TREE, cv.CHAIN_APPROX_NONE)\n",
    "    for cnt in contours:\n",
    "        cv.drawContours(mask, [cnt], -1, (255, 255, 255), -1)\n",
    "\n",
    "    mask = cv.cvtColor(mask, cv.COLOR_BGR2GRAY)\n",
    "    # morphological operations\n",
    "    out = cv.erode(mask, kernel, iterations=1)\n",
    "    out = cv.dilate(mask, kernel, iterations=1)\n",
    "\n",
    "    cv.imwrite(\"output/post_processing/\" + row.filename, out)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "outputs": [],
   "source": [
    "df.apply(apply_post_processing, axis=1);"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df.apply(concatenate_and_write, axis=1);"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "def shape_recognition(row):\n",
    "    img = cv.imread(row.path)\n",
    "    processed = cv.imread(\"output/post_processing/\" + row.filename, 0)\n",
    "\n",
    "    _, thresh = cv.threshold(processed, 240, 255, cv.CHAIN_APPROX_NONE)\n",
    "    contours, _ = cv.findContours(thresh, cv.RETR_TREE, cv.CHAIN_APPROX_NONE)\n",
    "\n",
    "    contours = sorted(contours, key=lambda x: -cv.contourArea(x))[:5]\n",
    "\n",
    "    shapes = []\n",
    "\n",
    "    for contour in contours:\n",
    "        if float(cv.contourArea(contour) / (img.shape[0]*img.shape[1])) >= 0.95:\n",
    "            continue\n",
    "        approx = cv.approxPolyDP(contour, 0.01*cv.arcLength(contour, True), True)\n",
    "        if len(approx) == 4:\n",
    "            shapes.append((\"rectangle\", cv.contourArea(contour), (cv.boundingRect(contour))))\n",
    "        elif len(approx) == 8:\n",
    "            shapes.append((\"octagon\", cv.contourArea(contour), (cv.boundingRect(contour))))\n",
    "        elif len(approx) > 8:\n",
    "            shapes.append((\"circle\", cv.contourArea(contour), (cv.boundingRect(contour))))\n",
    "\n",
    "    return shapes"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "df[\"shapes\"] = df.apply(shape_recognition, axis=1);"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [],
   "source": [
    "def classify(row):\n",
    "    shapes = row.shapes\n",
    "    if len(shapes) == 0:\n",
    "        return -1\n",
    "\n",
    "    shape = shapes[0]\n",
    "\n",
    "    if shape[0] == 'circle':\n",
    "        return 0\n",
    "    elif shape[0] == 'rectangle':\n",
    "        return 1\n",
    "    elif shape[0] == 'octagon':\n",
    "        return 2\n",
    "\n",
    "    return -1\n",
    "\n",
    "df[\"classification\"] = df.apply(classify, axis=1);"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 67.28%\n"
     ]
    }
   ],
   "source": [
    "accuracy = metrics.accuracy_score(df[\"class\"], df[\"classification\"])\n",
    "\n",
    "print(\"Accuracy: {:.02f}%\".format(accuracy*100))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}