{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Traffic sign detection and classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [],
   "source": [
    "from xml.dom import minidom\n",
    "from os import walk\n",
    "import pandas as pd\n",
    "import cv2 as cv\n",
    "import numpy as np\n",
    "from sklearn import metrics\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "filenames = next(walk(\"res/annotations\"), (None, None, []))[2]  # [] if no file\n",
    "\n",
    "signs = []\n",
    "\n",
    "for annotation in filenames:\n",
    "    # parse an xml file by name\n",
    "    file = minidom.parse(\"res/annotations/\" + annotation)\n",
    "\n",
    "    #use getElementsByTagName() to get tag\n",
    "    path = \"res/images/\" + file.getElementsByTagName('filename')[0].firstChild.data\n",
    "    filename = file.getElementsByTagName('filename')[0].firstChild.data\n",
    "    name = file.getElementsByTagName('name')[0].firstChild.data\n",
    "    # truncated = file.getElementsByTagName('truncated')[0].firstChild.data\n",
    "    # occluded = file.getElementsByTagName('occluded')[0].firstChild.data\n",
    "    # difficult = file.getElementsByTagName('difficult')[0].firstChild.data\n",
    "\n",
    "    if name == \"trafficlight\":\n",
    "        continue\n",
    "\n",
    "    signs.append([filename, name, path])\n",
    "\n",
    "df = pd.DataFrame(signs, columns=['filename', 'name', 'path'])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "def condition_classes(s):\n",
    "    if s['name'] == 'speedlimit':\n",
    "        return 0\n",
    "    elif s[\"name\"] == 'crosswalk':\n",
    "        return 1\n",
    "    elif s[\"name\"] == \"stop\":\n",
    "        return 2\n",
    "\n",
    "\n",
    "df[\"class\"] = df.apply(condition_classes, axis=1)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "def concatenate_and_write(row):\n",
    "    img = cv.imread(row.path)\n",
    "    hist = cv.imread(\"output/histogram/\" + row.filename)\n",
    "    segm = cv.imread(\"output/segmentation/\" + row.filename)\n",
    "    post = cv.imread(\"output/post_processing/\" + row.filename)\n",
    "\n",
    "    vis = np.concatenate((img, hist, segm, post), axis=1)\n",
    "\n",
    "    cv.imwrite(\"output/concatenated/\" + row.filename, vis)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Step 1 - Histogram equalization\n",
    "\n",
    "TODO - Need to improve the histogram equalization"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "def apply_histogram_equalization(row):\n",
    "    img = cv.imread(row.path)\n",
    "    # convert image from RGB to HSV\n",
    "    img_hsv = cv.cvtColor(img, cv.COLOR_BGR2HSV)\n",
    "    # Histogram equalisation on the V-channel\n",
    "    img_hsv[:, :, 2] = cv.equalizeHist(img_hsv[:, :, 2])\n",
    "    # convert image back from HSV to RGB\n",
    "    out = cv.cvtColor(img_hsv, cv.COLOR_HSV2BGR)\n",
    "\n",
    "    cv.imwrite(\"output/histogram/\" + row.filename, out)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "df.apply(apply_histogram_equalization, axis=1);"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Step 2 - Segmentation by Color"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "def apply_segmentation(row):\n",
    "    img = cv.imread(row.path)\n",
    "    # TODO - work on histogram equalization\n",
    "    # img_hist = cv.imread(\"output/histogram/\" + row.filename)\n",
    "    img_hist = img\n",
    "    img_hsv = cv.cvtColor(img_hist, cv.COLOR_BGR2HSV)\n",
    "\n",
    "    lower_red_m1 = (0, 70, 60)\n",
    "    upper_red_m1 = (10, 255, 255)\n",
    "\n",
    "    lower_red_m2 = (170, 70, 60)\n",
    "    upper_red_m2 = (180, 255, 255)\n",
    "\n",
    "    lower_blue_m3 = (94, 127, 20)\n",
    "    upper_blue_m3 = (126, 255, 200)\n",
    "\n",
    "    mask1 = cv.inRange(img_hsv, lower_red_m1, upper_red_m1)\n",
    "    mask2 = cv.inRange(img_hsv, lower_red_m2, upper_red_m2)\n",
    "    mask3 = cv.inRange(img_hsv, lower_blue_m3, upper_blue_m3)\n",
    "\n",
    "    mask = mask1 + mask2 + mask3\n",
    "\n",
    "    # out = cv.bitwise_and(img_hist, img_hist, mask=mask)\n",
    "\n",
    "    cv.imwrite(\"output/segmentation/\" + row.filename, mask)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "df.apply(apply_segmentation, axis=1);"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Step 3 - Post-Processing"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "def apply_post_processing(row):\n",
    "    img = cv.imread(row.path)\n",
    "    segm_img = cv.imread(\"output/segmentation/\" + row.filename, cv.IMREAD_GRAYSCALE)\n",
    "\n",
    "    # apply median filter to remove noise\n",
    "    out = cv.medianBlur(segm_img, 5)\n",
    "    rows, cols = out.shape\n",
    "\n",
    "    # Taking a matrix of size 5 as the kernel\n",
    "    kernel = np.ones((5, 5), np.uint8)\n",
    "\n",
    "    # morphological operations\n",
    "    out = cv.dilate(out, kernel, iterations=1)\n",
    "    out = cv.erode(out, kernel, iterations=1)\n",
    "\n",
    "    # remove small and weird objects\n",
    "    contours, hierarchy = cv.findContours(out, cv.RETR_TREE, cv.CHAIN_APPROX_SIMPLE)\n",
    "    for contour in contours:\n",
    "        x, y, w, h = cv.boundingRect(contour)\n",
    "        aspect_ratio = float(w) / h\n",
    "        if cv.contourArea(contour) < 1 / 1500.0 * rows * cols and (aspect_ratio > 0.5 or aspect_ratio < 1.3):\n",
    "            out = cv.fillPoly(out, pts=contour, color=(0, 0, 0))\n",
    "\n",
    "    mask = np.full(img.shape, 0, \"uint8\")\n",
    "    contours, hierarchies = cv.findContours(out, cv.RETR_TREE, cv.CHAIN_APPROX_NONE)\n",
    "    for cnt in contours:\n",
    "        cv.drawContours(mask, [cnt], -1, (255, 255, 255), -1)\n",
    "\n",
    "    mask = cv.cvtColor(mask, cv.COLOR_BGR2GRAY)\n",
    "    # morphological operations\n",
    "    out = cv.erode(mask, kernel, iterations=1)\n",
    "    out = cv.dilate(mask, kernel, iterations=1)\n",
    "\n",
    "    cv.imwrite(\"output/post_processing/\" + row.filename, out)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "outputs": [],
   "source": [
    "df.apply(apply_post_processing, axis=1);"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df.apply(concatenate_and_write, axis=1);"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "def shape_recognition(row):\n",
    "    img = cv.imread(row.path)\n",
    "    processed = cv.imread(\"output/post_processing/\" + row.filename, 0)\n",
    "\n",
    "    _, thresh = cv.threshold(processed, 240, 255, cv.CHAIN_APPROX_NONE)\n",
    "    contours, _ = cv.findContours(thresh, cv.RETR_TREE, cv.CHAIN_APPROX_NONE)\n",
    "\n",
    "    contours = sorted(contours, key=lambda x: -cv.contourArea(x))[:5]\n",
    "\n",
    "    shapes = []\n",
    "\n",
    "    for contour in contours:\n",
    "        if float(cv.contourArea(contour) / (img.shape[0]*img.shape[1])) >= 0.95:\n",
    "            continue\n",
    "        approx = cv.approxPolyDP(contour, 0.01*cv.arcLength(contour, True), True)\n",
    "        if len(approx) == 4:\n",
    "            shapes.append((\"rectangle\", cv.contourArea(contour), (cv.boundingRect(contour))))\n",
    "        elif len(approx) == 8:\n",
    "            shapes.append((\"octagon\", cv.contourArea(contour), (cv.boundingRect(contour))))\n",
    "        elif len(approx) > 8:\n",
    "            shapes.append((\"circle\", cv.contourArea(contour), (cv.boundingRect(contour))))\n",
    "\n",
    "    return shapes"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "df[\"shapes\"] = df.apply(shape_recognition, axis=1);"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "outputs": [],
   "source": [
    "def classify(row):\n",
    "    shapes_info = row.shapes\n",
    "    if len(shapes_info) == 0:\n",
    "        return -1\n",
    "\n",
    "    shapes = [x[0] for x in shapes_info]\n",
    "    shape = shapes[0]\n",
    "\n",
    "    # octagon shape is dominant but we need to check if the other shapes detected are larger\n",
    "    if \"octagon\" in shapes and abs(shapes_info[shapes.index(\"octagon\")][1] - shapes_info[0][1]) < 500:\n",
    "        return 2\n",
    "\n",
    "    if shape == 'circle':\n",
    "        return 0\n",
    "    elif shape == 'rectangle':\n",
    "        return 1\n",
    "\n",
    "    return -1\n",
    "\n",
    "df[\"classification\"] = df.apply(classify, axis=1);"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 64.34%\n"
     ]
    },
    {
     "data": {
      "text/plain": "        filename        name                    path  class  \\\n0    road100.png  speedlimit  res/images/road100.png      0   \n1    road101.png  speedlimit  res/images/road101.png      0   \n2    road102.png  speedlimit  res/images/road102.png      0   \n3    road103.png  speedlimit  res/images/road103.png      0   \n4    road104.png  speedlimit  res/images/road104.png      0   \n..           ...         ...                     ...    ...   \n811   road95.png        stop   res/images/road95.png      2   \n812   road96.png        stop   res/images/road96.png      2   \n813   road97.png        stop   res/images/road97.png      2   \n814   road98.png        stop   res/images/road98.png      2   \n815   road99.png        stop   res/images/road99.png      2   \n\n                                                 shape  \\\n0                [(circle, 69936.0, (0, 0, 400, 385))]   \n1    [(circle, 6606.5, (200, 6, 163, 184)), (circle...   \n2               [(circle, 3435.0, (30, 37, 191, 230))]   \n3              [(circle, 37738.0, (91, 27, 206, 244))]   \n4              [(circle, 76501.0, (47, 16, 298, 329))]   \n..                                                 ...   \n811  [(circle, 7784.0, (98, 97, 164, 121)), (circle...   \n812  [(circle, 10047.0, (213, 59, 108, 121)), (circ...   \n813             [(circle, 65614.0, (0, 85, 400, 182))]   \n814          [(octagon, 40907.5, (141, 20, 232, 218))]   \n815  [(circle, 28148.0, (41, 34, 184, 193)), (circl...   \n\n                                                shapes  classification  \n0                [(circle, 69936.0, (0, 0, 400, 385))]               0  \n1    [(circle, 6606.5, (200, 6, 163, 184)), (circle...               0  \n2               [(circle, 3435.0, (30, 37, 191, 230))]               0  \n3              [(circle, 37738.0, (91, 27, 206, 244))]               0  \n4              [(circle, 76501.0, (47, 16, 298, 329))]               0  \n..                                                 ...             ...  \n811  [(circle, 7784.0, (98, 97, 164, 121)), (circle...               0  \n812  [(circle, 10047.0, (213, 59, 108, 121)), (circ...               0  \n813             [(circle, 65614.0, (0, 85, 400, 182))]               0  \n814          [(octagon, 40907.5, (141, 20, 232, 218))]               2  \n815  [(circle, 28148.0, (41, 34, 184, 193)), (circl...               0  \n\n[816 rows x 7 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>filename</th>\n      <th>name</th>\n      <th>path</th>\n      <th>class</th>\n      <th>shape</th>\n      <th>shapes</th>\n      <th>classification</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>road100.png</td>\n      <td>speedlimit</td>\n      <td>res/images/road100.png</td>\n      <td>0</td>\n      <td>[(circle, 69936.0, (0, 0, 400, 385))]</td>\n      <td>[(circle, 69936.0, (0, 0, 400, 385))]</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>road101.png</td>\n      <td>speedlimit</td>\n      <td>res/images/road101.png</td>\n      <td>0</td>\n      <td>[(circle, 6606.5, (200, 6, 163, 184)), (circle...</td>\n      <td>[(circle, 6606.5, (200, 6, 163, 184)), (circle...</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>road102.png</td>\n      <td>speedlimit</td>\n      <td>res/images/road102.png</td>\n      <td>0</td>\n      <td>[(circle, 3435.0, (30, 37, 191, 230))]</td>\n      <td>[(circle, 3435.0, (30, 37, 191, 230))]</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>road103.png</td>\n      <td>speedlimit</td>\n      <td>res/images/road103.png</td>\n      <td>0</td>\n      <td>[(circle, 37738.0, (91, 27, 206, 244))]</td>\n      <td>[(circle, 37738.0, (91, 27, 206, 244))]</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>road104.png</td>\n      <td>speedlimit</td>\n      <td>res/images/road104.png</td>\n      <td>0</td>\n      <td>[(circle, 76501.0, (47, 16, 298, 329))]</td>\n      <td>[(circle, 76501.0, (47, 16, 298, 329))]</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>811</th>\n      <td>road95.png</td>\n      <td>stop</td>\n      <td>res/images/road95.png</td>\n      <td>2</td>\n      <td>[(circle, 7784.0, (98, 97, 164, 121)), (circle...</td>\n      <td>[(circle, 7784.0, (98, 97, 164, 121)), (circle...</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>812</th>\n      <td>road96.png</td>\n      <td>stop</td>\n      <td>res/images/road96.png</td>\n      <td>2</td>\n      <td>[(circle, 10047.0, (213, 59, 108, 121)), (circ...</td>\n      <td>[(circle, 10047.0, (213, 59, 108, 121)), (circ...</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>813</th>\n      <td>road97.png</td>\n      <td>stop</td>\n      <td>res/images/road97.png</td>\n      <td>2</td>\n      <td>[(circle, 65614.0, (0, 85, 400, 182))]</td>\n      <td>[(circle, 65614.0, (0, 85, 400, 182))]</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>814</th>\n      <td>road98.png</td>\n      <td>stop</td>\n      <td>res/images/road98.png</td>\n      <td>2</td>\n      <td>[(octagon, 40907.5, (141, 20, 232, 218))]</td>\n      <td>[(octagon, 40907.5, (141, 20, 232, 218))]</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>815</th>\n      <td>road99.png</td>\n      <td>stop</td>\n      <td>res/images/road99.png</td>\n      <td>2</td>\n      <td>[(circle, 28148.0, (41, 34, 184, 193)), (circl...</td>\n      <td>[(circle, 28148.0, (41, 34, 184, 193)), (circl...</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n<p>816 rows Ã— 7 columns</p>\n</div>"
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy = metrics.accuracy_score(df[\"class\"], df[\"classification\"])\n",
    "\n",
    "print(\"Accuracy: {:.02f}%\".format(accuracy*100))\n",
    "\n",
    "df"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}