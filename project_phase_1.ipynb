{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Traffic sign detection and classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from xml.dom import minidom\n",
    "from os import walk\n",
    "import pandas as pd\n",
    "import cv2 as cv\n",
    "import numpy as np\n",
    "from sklearn import metrics\n",
    "import openpyxl\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "filenames = next(walk(\"res/annotations\"), (None, None, []))[2]  # [] if no file\n",
    "\n",
    "signs = []\n",
    "\n",
    "for annotation in filenames:\n",
    "    # parse an xml file by name\n",
    "    file = minidom.parse(\"res/annotations/\" + annotation)\n",
    "    if len(file.getElementsByTagName('name')) == 1:\n",
    "        #use getElementsByTagName() to get tag\n",
    "        path = \"res/images/\" + file.getElementsByTagName('filename')[0].firstChild.data\n",
    "        filename = file.getElementsByTagName('filename')[0].firstChild.data\n",
    "        name = file.getElementsByTagName('name')[0].firstChild.data\n",
    "        # truncated = file.getElementsByTagName('truncated')[0].firstChild.data\n",
    "        # occluded = file.getElementsByTagName('occluded')[0].firstChild.data\n",
    "        # difficult = file.getElementsByTagName('difficult')[0].firstChild.data\n",
    "\n",
    "        if name == \"trafficlight\":\n",
    "            continue\n",
    "\n",
    "        signs.append([filename, name, path])\n",
    "\n",
    "df = pd.DataFrame(signs, columns=['filename', 'name', 'path'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def condition_classes(s):\n",
    "    if s['name'] == 'speedlimit':\n",
    "        return 0\n",
    "    elif s[\"name\"] == 'crosswalk':\n",
    "        return 1\n",
    "    elif s[\"name\"] == \"stop\":\n",
    "        return 2\n",
    "\n",
    "\n",
    "df[\"class\"] = df.apply(condition_classes, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def concatenate_and_write(row):\n",
    "    img = cv.imread(row.path)\n",
    "    hist = cv.imread(\"output/histogram/\" + row.filename)\n",
    "    segm = cv.imread(\"output/segmentation/\" + row.filename)\n",
    "    post = cv.imread(\"output/post_processing/\" + row.filename)\n",
    "    anno = cv.imread(\"output/annotations/\" + row.filename)\n",
    "\n",
    "    vis = np.concatenate((img, hist, segm, anno, post), axis=1)\n",
    "\n",
    "    cv.imwrite(\"output/concatenated/\" + row.filename, vis)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1 - Histogram equalization\n",
    "\n",
    "TODO - Need to improve the histogram equalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def apply_histogram_equalization(row):\n",
    "    img = cv.imread(row.path)\n",
    "    lab = cv.cvtColor(img, cv.COLOR_BGR2LAB)\n",
    "\n",
    "    clahe = cv.createCLAHE(clipLimit=10.0,tileGridSize=(8,8))\n",
    "\n",
    "    lab[...,0] = clahe.apply(lab[...,0])\n",
    "\n",
    "    out = cv.cvtColor(lab, cv.COLOR_LAB2BGR)\n",
    "\n",
    "    cv.imwrite(\"output/histogram/\" + row.filename, out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "df.apply(apply_histogram_equalization, axis=1);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Step 2 - Segmentation by Color"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def apply_segmentation(row):\n",
    "    img = cv.imread(row.path)\n",
    "    # TODO - work on histogram equalization\n",
    "    img_hist = cv.imread(\"output/histogram/\" + row.filename)\n",
    "    img_hsv = cv.cvtColor(img_hist, cv.COLOR_BGR2HSV)\n",
    "\n",
    "    lower_red_m1 = (0, 70, 60)\n",
    "    upper_red_m1 = (10, 255, 255)\n",
    "\n",
    "    lower_red_m2 = (170, 70, 60)\n",
    "    upper_red_m2 = (180, 255, 255)\n",
    "\n",
    "    lower_blue_m3 = (94, 127, 20)\n",
    "    upper_blue_m3 = (126, 255, 200)\n",
    "\n",
    "    mask1 = cv.inRange(img_hsv, lower_red_m1, upper_red_m1)\n",
    "    mask2 = cv.inRange(img_hsv, lower_red_m2, upper_red_m2)\n",
    "    mask3 = cv.inRange(img_hsv, lower_blue_m3, upper_blue_m3)\n",
    "\n",
    "    mask = mask1 + mask2 + mask3\n",
    "\n",
    "    # out = cv.bitwise_and(img_hist, img_hist, mask=mask)\n",
    "\n",
    "    cv.imwrite(\"output/segmentation/\" + row.filename, mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "df.apply(apply_segmentation, axis=1);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Step 3 - Post-Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def apply_post_processing(row):\n",
    "    img = cv.imread(row.path)\n",
    "    segm_img = cv.imread(\"output/segmentation/\" + row.filename, cv.IMREAD_GRAYSCALE)\n",
    "\n",
    "    # apply median filter to remove noise\n",
    "    out = cv.medianBlur(segm_img, 5)\n",
    "    rows, cols = out.shape\n",
    "    \n",
    "    # Taking a matrix of size 5 as the kernel\n",
    "    kernel = np.ones((5, 5), np.uint8)\n",
    "\n",
    "    # morphological operations\n",
    "    out = cv.morphologyEx(out, cv.MORPH_CLOSE, kernel, iterations=3)\n",
    "\n",
    "    # remove small and weird objects\n",
    "    contours, hierarchy = cv.findContours(out, cv.RETR_TREE, cv.CHAIN_APPROX_SIMPLE)[-2:]\n",
    "    for contour in contours:\n",
    "        x, y, w, h = cv.boundingRect(contour)\n",
    "        aspect_ratio = float(w) / h\n",
    "        if cv.contourArea(contour) < 1 / 1500.0 * rows * cols and (aspect_ratio > 0.5 or aspect_ratio < 1.3):\n",
    "            out = cv.fillPoly(out, pts=contour, color=(0, 0, 0))\n",
    "\n",
    "    mask = np.full(img.shape, 0, \"uint8\")\n",
    "    contours, hierarchies = cv.findContours(out, cv.RETR_TREE, cv.CHAIN_APPROX_NONE)[-2:]\n",
    "    for cnt in contours:\n",
    "        cv.drawContours(mask, [cnt], -1, (255, 255, 255), -1)\n",
    "\n",
    "    mask = cv.cvtColor(mask, cv.COLOR_BGR2GRAY)\n",
    "    # morphological operations\n",
    "    out = cv.erode(mask, kernel, iterations=1)\n",
    "    # out = cv.dilate(out, kernel, iterations=1)\n",
    "\n",
    "    cv.imwrite(\"output/post_processing/\" + row.filename, out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "df.apply(apply_post_processing, axis=1);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4 - Find Connected Components"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def connected_component(row):\n",
    "    original = cv.imread(row.path)\n",
    "    img = cv.imread('output/segmentation/' + row.filename, 0)\n",
    "    # apply median filter to remove noise\n",
    "    img = cv.medianBlur(img, 5)\n",
    "    \n",
    "    output = cv.connectedComponentsWithStats(img, 4, cv.CV_32S)\n",
    "    (numLabels, labels, stats, centroids) = output\n",
    "    \n",
    "    output = original.copy()\n",
    "    \n",
    "    components = []\n",
    "    \n",
    "    # loop over the number of unique connected component labels\n",
    "    for i in range(0, numLabels):\n",
    "        # if this is the first component then we examine the\n",
    "        # *background* (typically we would just ignore this\n",
    "        # component in our loop)\n",
    "        if i == 0:\n",
    "            continue\n",
    "        # otherwise, we are examining an actual connected component\n",
    "        # extract the connected component statistics and centroid for\n",
    "        # the current label\n",
    "        x = stats[i, cv.CC_STAT_LEFT]\n",
    "        y = stats[i, cv.CC_STAT_TOP]\n",
    "        w = stats[i, cv.CC_STAT_WIDTH]\n",
    "        h = stats[i, cv.CC_STAT_HEIGHT]\n",
    "        area = stats[i, cv.CC_STAT_AREA]\n",
    "        (cX, cY) = centroids[i]\n",
    "        \n",
    "        if 0.8 > float(w)/h or float(w)/h > 1.3:\n",
    "            continue\n",
    "        \n",
    "        components.append((x,y,w,h,cX,cY))\n",
    "        \n",
    "        cv.rectangle(output, (x, y), (x + w, y + h), (0, 255, 0), 3)\n",
    "        cv.circle(output, (int(cX), int(cY)), 4, (0, 0, 255), -1)\n",
    "        \n",
    "        \n",
    "    cv.imwrite('output/annotations/' + row.filename, output)\n",
    "    \n",
    "    return sorted(components, key=lambda x: x[2]*x[3])[:4]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"components\"] = df.apply(connected_component, axis=1);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "df.apply(concatenate_and_write, axis=1);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4 - Shape Recognition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def shape_recognition(row):\n",
    "    img = cv.imread(row.path)\n",
    "    processed = cv.imread(\"output/post_processing/\" + row.filename, 0)\n",
    "\n",
    "    _, thresh = cv.threshold(processed, 240, 255, cv.CHAIN_APPROX_NONE)\n",
    "    contours, _ = cv.findContours(thresh, cv.RETR_TREE, cv.CHAIN_APPROX_NONE)[-2:]\n",
    "\n",
    "    contours = sorted(contours, key=lambda x: -cv.contourArea(x))[:10]\n",
    "\n",
    "    shapes = []\n",
    "\n",
    "    for contour in contours:\n",
    "        if float(cv.contourArea(contour) / (img.shape[0]*img.shape[1])) >= 0.95:\n",
    "            continue\n",
    "        approx = cv.approxPolyDP(contour, 0.01*cv.arcLength(contour, True), True)\n",
    "        if len(approx) == 4:\n",
    "            shapes.append((\"rectangle\", cv.contourArea(contour), (cv.boundingRect(contour))))\n",
    "        elif len(approx) == 8:\n",
    "            shapes.append((\"octagon\", cv.contourArea(contour), (cv.boundingRect(contour))))\n",
    "        elif len(approx) > 8:\n",
    "            shapes.append((\"circle\", cv.contourArea(contour), (cv.boundingRect(contour))))\n",
    "\n",
    "    return shapes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "df[\"shapes\"] = df.apply(shape_recognition, axis=1);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_roi(filename, roi):\n",
    "    x,y,w,h,cX,cY = roi\n",
    "    \n",
    "    img = cv.imread('output/histogram/' + filename)\n",
    "    img = img[y:(y+h),x:(x+w)]\n",
    "    \n",
    "    aux = np.full((h+50, w+50, 3), 0, \"uint8\")\n",
    "    aux[25:25+h, 25:25+w] = img\n",
    "    img = aux\n",
    "    \n",
    "    img_hsv = cv.cvtColor(img, cv.COLOR_BGR2HSV)\n",
    "    \n",
    "    lower_red_m1 = (0, 70, 60)\n",
    "    upper_red_m1 = (10, 255, 255)\n",
    "\n",
    "    lower_red_m2 = (170, 70, 60)\n",
    "    upper_red_m2 = (180, 255, 255)\n",
    "\n",
    "    lower_blue_m3 = (94, 127, 20)\n",
    "    upper_blue_m3 = (126, 255, 200)\n",
    "\n",
    "    mask1 = cv.inRange(img_hsv, lower_red_m1, upper_red_m1)\n",
    "    mask2 = cv.inRange(img_hsv, lower_red_m2, upper_red_m2)\n",
    "    mask_red = mask1 + mask2\n",
    "    \n",
    "    mask_blue = cv.inRange(img_hsv, lower_blue_m3, upper_blue_m3)\n",
    "\n",
    "    ratio_red = cv.countNonZero(mask_red)/(img.size/3)\n",
    "    ratio_blue = cv.countNonZero(mask_blue)/(img.size/3)\n",
    "    \n",
    "    processed = None\n",
    "    if ratio_red > ratio_blue:\n",
    "        processed = mask_red\n",
    "    else:\n",
    "        processed = mask_blue\n",
    "          \n",
    "        \n",
    "    # Taking a matrix of size 5 as the kernel\n",
    "    kernel = np.ones((10, 10), np.uint8)\n",
    "\n",
    "    # morphological operations\n",
    "    processed = cv.morphologyEx(processed, cv.MORPH_CLOSE, kernel, iterations=3)\n",
    "        \n",
    "    _, thresh = cv.threshold(processed, 240, 255, cv.CHAIN_APPROX_NONE)\n",
    "    contours, _ = cv.findContours(thresh, cv.RETR_TREE, cv.CHAIN_APPROX_NONE)[-2:]\n",
    "    \n",
    "\n",
    "    contours = sorted(contours, key=lambda x: -cv.contourArea(x))[:10]\n",
    "\n",
    "    shapes = []\n",
    "\n",
    "    for contour in contours:\n",
    "        if float(cv.contourArea(contour) / (img.shape[0]*img.shape[1])) >= 0.95:\n",
    "            continue\n",
    "        approx = cv.approxPolyDP(contour, 0.01*cv.arcLength(contour, True), True)\n",
    "        if len(approx) == 4:\n",
    "            shapes.append((\"rectangle\", cv.contourArea(contour), (cv.boundingRect(contour))))\n",
    "        elif len(approx) == 8:\n",
    "            shapes.append((\"octagon\", cv.contourArea(contour), (cv.boundingRect(contour))))\n",
    "        elif len(approx) > 8:\n",
    "            # check if there are hough circles\n",
    "            circles_img = cv.HoughCircles(processed,cv.HOUGH_GRADIENT,1,20,\n",
    "                                          param1=50,\n",
    "                                          param2=30,\n",
    "                                          minRadius=int(w*0.333),\n",
    "                                          maxRadius=0)\n",
    "            if circles_img is not None:      \n",
    "                shapes.append((\"circle\", cv.contourArea(contour), (cv.boundingRect(contour)))) \n",
    "    \n",
    "    if len(shapes) == 0:\n",
    "        return 'undefined', ratio_red, ratio_blue\n",
    "    \n",
    "    if shapes[0][0] == 'circle':\n",
    "        return 'circle', ratio_red, ratio_blue\n",
    "    elif shapes[0][0] == 'rectangle':\n",
    "        return 'rectangle', ratio_red, ratio_blue\n",
    "    elif shapes[0][0] == 'octagon':\n",
    "        return 'octagon', ratio_red, ratio_blue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cc_detect(row):\n",
    "    img = cv.imread(row.path)\n",
    "    lst = []\n",
    "    for component in row.components:\n",
    "        if (component[2] * component[3]) / (img.shape[0]*img.shape[1]) < 0.2:\n",
    "            continue\n",
    "        lst.append(process_roi(row.filename, component))\n",
    "    \n",
    "    return lst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"cc_guess\"] = df.apply(cc_detect, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def classify(row):\n",
    "    img = cv.imread(row.path)\n",
    "    \n",
    "    shapes = row.shapes\n",
    "    if len(shapes) == 0:\n",
    "        return {'circle': 0, 'rectangle': 0, 'octagon': 0, 'undefined': 1}\n",
    "    \n",
    "    guesses = {'circle': 0, 'rectangle': 0, 'octagon': 0, 'undefined': 0}\n",
    "    \n",
    "    guesses[shapes[0][0]] += 1.5\n",
    "\n",
    "    # now try to see if the intermediate step has a better fit, or validates current guess\n",
    "    \n",
    "    for component in row.components:\n",
    "        # print(list(component))\n",
    "        if (component[2] * component[3]) / (img.shape[0]*img.shape[1]) < 0.2:\n",
    "            continue\n",
    "        next_guess, ratio_red, ratio_blue = process_roi(row.filename, component)\n",
    "        acc = 0\n",
    "        \n",
    "        if next_guess == 'circle':\n",
    "            acc += 0.3333\n",
    "            if ratio_red > 0.05:\n",
    "                acc += 0.3333\n",
    "            else:\n",
    "                acc -= 0.1111 \n",
    "                \n",
    "        if next_guess == 'rectangle':\n",
    "            acc += 1.3333\n",
    "            if ratio_blue > 0.05:\n",
    "                acc += 0.3333\n",
    "            else:\n",
    "                acc -= 0.1111\n",
    "            \n",
    "        if next_guess == 'octagon':\n",
    "            acc += 1.5\n",
    "            if ratio_red > 0.4:\n",
    "                acc += 1.5\n",
    "            elif ratio_red < ratio_blue:\n",
    "                acc -= 0.5\n",
    "        \n",
    "        guesses[next_guess] += acc\n",
    "        \n",
    "    return guesses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"guess\"] = df.apply(classify, axis=1);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_classification(row):\n",
    "    guesses = row.guess\n",
    "    guess = max(guesses, key=guesses.get)\n",
    "    \n",
    "    if guess == 'circle':\n",
    "        return 0\n",
    "    elif guess == 'rectangle':\n",
    "        return 1\n",
    "    elif guess == 'octagon':\n",
    "        return 2\n",
    "    else:\n",
    "        return -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"classification\"] = df.apply(apply_classification, axis=1);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classes:\n",
      " 0    481\n",
      "2     65\n",
      "1     42\n",
      "Name: class, dtype: int64\n",
      "Detected classes:\n",
      "  0    501\n",
      " 2     53\n",
      "-1     18\n",
      " 1     16\n",
      "Name: classification, dtype: int64\n",
      "Accuracy Total: 81.97%\n",
      "Accuracy Signs Found: 84.56%\n"
     ]
    }
   ],
   "source": [
    "df_found = df[df[\"classification\"] != -1]\n",
    "\n",
    "accuracy_total = metrics.accuracy_score(df[\"class\"], df[\"classification\"])\n",
    "accuracy_found = metrics.accuracy_score(df_found[\"class\"], df_found[\"classification\"])\n",
    "\n",
    "print(\"Classes:\\n\", df[\"class\"].value_counts())\n",
    "print(\"Detected classes:\\n\", df[\"classification\"].value_counts())\n",
    "print(\"Accuracy Total: {:.02f}%\".format(accuracy_total*100))\n",
    "print(\"Accuracy Signs Found: {:.02f}%\".format(accuracy_found*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class 0: ✓:441|✕:40\n",
      "Class 1: ✓:11|✕:31\n",
      "Class 2: ✓:30|✕:35\n"
     ]
    }
   ],
   "source": [
    "failed_0 = len(df[(df[\"class\"] == 0) & (df[\"classification\"] != 0)])\n",
    "failed_1 = len(df[(df[\"class\"] == 1) & (df[\"classification\"] != 1)])\n",
    "failed_2 = len(df[(df[\"class\"] == 2) & (df[\"classification\"] != 2)])\n",
    "\n",
    "right_0 = len(df[(df[\"class\"] == 0) & (df[\"classification\"] == 0)])\n",
    "right_1 = len(df[(df[\"class\"] == 1) & (df[\"classification\"] == 1)])\n",
    "right_2 = len(df[(df[\"class\"] == 2) & (df[\"classification\"] == 2)])\n",
    "\n",
    "\n",
    "print(\"Class 0: ✓:{}|✕:{}\".format(right_0, failed_0))\n",
    "print(\"Class 1: ✓:{}|✕:{}\".format(right_1, failed_1))\n",
    "print(\"Class 2: ✓:{}|✕:{}\".format(right_2, failed_2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extra: Save Results Table on a Webpage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.core.display import HTML\n",
    "\n",
    "def append_images(row):\n",
    "    return \"output/concatenated/\" + row.filename\n",
    "\n",
    "def append_result(row):\n",
    "    return row.classification is row[\"class\"]\n",
    "\n",
    "def path_to_image_html(path):\n",
    "    return '<a target=\"_blank\" href=\"' + path + '\"><img src=\"'+ path + '\" width=\"100\" ></a>'\n",
    "\n",
    "\n",
    "df[\"result\"] = df.apply(append_result, axis=1)\n",
    "df[\"image\"] = df.apply(append_images, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.sort_values(by=['class'], ascending=False)\n",
    "df.to_html('results.html', escape=False, formatters=dict(image=path_to_image_html))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
